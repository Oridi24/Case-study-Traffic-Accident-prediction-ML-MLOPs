#  *Predicci칩n de la gravedad de los accidentes de tr치fico* 游뚽

## 游댍 *Descripci칩n del caso de estudio*
*La siniestralidad vial es un problema con gran impacto social y econ칩mico. Poder anticipar la **severidad de un accidente** permite a las autoridades y servicios de emergencia **optimizar la asignaci칩n de recursos** y dise침ar medidas de prevenci칩n m치s efectivas.*  

*Este proyecto desarrolla un modelo predictivo robusto de clasificaci칩n binaria con t칠cnicas de **Machine Learning** capaz de predecir si un accidente de tr치fico ser치 **leve (0)** o **grave (1)**, a partir de informaci칩n contextual (condiciones de la v칤a, hora, d칤a de la semana, n칰mero de veh칤culos implicados, etc.)*. *El modelo final se despliega mediante **FastAPI**, ofreciendo un servicio accesible para realizar predicciones en tiempo real.*
*Esto permite:*
 - *Identificar accidentes de alto riesgo.*
 - *Priorizar recursos de atenci칩n y prevenci칩n vial.*
 - *Integrar un modelo ML en un sistema de alerta en tiempo real.*

---

## 游늭 *Estructura del Repositorio*: *Contenidos*

1. *Caso de estudio*: *Planteamiento del problema y objetivos del an치lisis.*
2. *Metodolog칤a de desarrollo*: *Enfoque de trabajo, fases del proyecto y t칠cnicas aplicadas.*
3. *Desarrollo del an치lisis predictivo*: *Descripci칩n del dataset (fuente: Kaggle), exploraci칩n inicial y preprocesamiento, ingenier칤a de caracter칤sticas, codificaci칩n, balanceo, entrenamiento y validaci칩n del modelo.*
4. *Desarrollo de API*: *Creaci칩n de una API en FastAPI para exponer el modelo entrenado y despliegue del algoritmo.*
5. *Presentaci칩n del proyecto*: *Slides resumen con objetivos, metodolog칤a, resultados y conclusiones.*
6. *Grabaci칩n de la presentaci칩n*: *Video con la exposici칩n del proyecto.*

---

##  游 *Dataset*

*El dataset incluye **167.444 registros** de accidentes, con variables como:*

- *Caracter칤sticas del accidente: tipo de choque, n칰mero de unidades involucradas.*
- *Condiciones de tr치fico: control de tr치fico, visibilidad, superficie de la carretera.*
- *Condiciones clim치ticas: lluvia, nieve, niebla, hielo.*
- *Variables temporales: hora, d칤a de la semana, mes.*

丘멆잺 ***Observaci칩n:** Dataset desbalanceado (~80% leve, ~20% grave).*

---

## 游 *Desarrollo*

### 1. ***Preprocesamiento:***
   - *Selecci칩n de variables relevantes.*
   - *Codificaci칩n de variables categ칩ricas y temporales.*
   - *No se gestionaron outliers para evitar eliminar la clase minoritaria.*
     
  
### 2. ***M칠tricas de evaluaci칩n:***  
| ***M칠trica***                 | ***Explicaci칩n Breve*** |
|---------------------------|-----------------|
| *Precision*               | *Mide la proporci칩n de predicciones positivas que fueron correctas. Responde a la pregunta: "De todas las que mi modelo dijo que eran positivas, 쯖u치ntas lo fueron realmente?"* |
| *Recall (Sensibilidad)*   | *Mide la proporci칩n de casos positivos reales que el modelo identific칩 correctamente. Responde a la pregunta: "De todos los casos positivos que hab칤a, 쯖u치ntos encontr칩 mi modelo?"* |
| *F1-score*                | *Es la media arm칩nica de Precision y Recall. Es 칰til para encontrar un equilibrio entre ambas m칠tricas, especialmente en clases desbalanceadas, ofreciendo un solo valor que las resume.* |
| *ROC-AUC*                 | *Mide la capacidad del modelo para distinguir entre clases. El valor representa la probabilidad de que el modelo clasifique un ejemplo positivo elegido al azar por encima de un ejemplo negativo elegido al azar. Un valor de 1.0 es perfecto, 0.5 es aleatorio.* |
| *Average Precision (AP)*  | *Mide el 치rea bajo la curva de Precision-Recall. Es especialmente relevante para clases desbalanceadas (como la clase "grave"), ya que se centra en la capacidad del modelo para identificar correctamente los casos positivos sin importar cu치ntos negativos se predigan.* |


### 3. ***Modelos evaluados:***
| ***Modelo***             | ***Explicaci칩n Breve** |
|-------------------|-----------------|
| *Decision Tree*    | *Un modelo que toma decisiones secuenciales al dividir los datos seg칰n diferentes caracter칤sticas. Funciona como un diagrama de flujo, donde cada nodo representa una prueba sobre una caracter칤stica y cada rama la salida de esa prueba. Es f치cil de interpretar.* |
| *Random Forest*    | *Un "bosque" de 치rboles de decisi칩n. Construye m칰ltiples 치rboles y promedia sus resultados para obtener una predicci칩n final. Reduce el sobreajuste y mejora la precisi칩n en comparaci칩n con un solo 치rbol de decisi칩n.* |
| *Gradient Boosting*| *Un modelo de conjunto que construye 치rboles de decisi칩n de forma secuencial. Cada nuevo 치rbol se entrena para corregir los errores del 치rbol anterior. Se centra en los errores de las predicciones previas, mejorando el rendimiento de forma incremental.* |
| *XGBoost (eXtreme Gradient Boosting)* | *Una implementaci칩n optimizada y altamente eficiente de Gradient Boosting. Es conocido por su velocidad y rendimiento, ya que incluye regularizaci칩n para evitar el sobreajuste y maneja bien los valores perdidos.* |
| *LogReg class_weight* | *Un m칠todo para la regresi칩n log칤stica (LogReg) que ajusta los pesos de las clases. Se utiliza para dar m치s importancia a la clase minoritaria durante el entrenamiento, lo que ayuda a mitigar el problema del desequilibrio de clases.* |
| *LogReg SMOTE*     | *Un m칠todo que combina la regresi칩n log칤stica con SMOTE (Synthetic Minority Over-sampling Technique). SMOTE crea ejemplos sint칠ticos de la clase minoritaria para equilibrar el conjunto de datos antes de entrenar el modelo, mejorando su capacidad para predecir correctamente la clase minoritaria.* |
| *Balanced RF*      | *Una variante de Random Forest que aborda el desequilibrio de clases. Durante la construcci칩n de cada 치rbol, utiliza un subconjunto de la clase mayoritaria de forma aleatoria para igualar el n칰mero de ejemplos con la clase minoritaria.* |
| *Easy Ensemble*    | *Un algoritmo de conjunto que crea varios subconjuntos de datos, cada uno con una fracci칩n de la clase mayoritaria y todos los ejemplos de la clase minoritaria. Entrena un clasificador para cada subconjunto y combina sus predicciones para la clasificaci칩n final.* |


### 4. ***T칠cnicas de validaci칩n cruzada:***
   - ***StratifiedKFold** para modelos de ensamble con clase minoritaria.*
   - ***GridSearchCV** para b칰squeda de hiperpar치metros en Logistic Regression y Random Forest.*

---


##  游늷 *Conclusiones generales:*

| ***Modelo***                     | ***Split*** | ***Accuracy*** | ***F1-score*** | ROC-AUC | ***Average Precision*** | ***Interpretaci칩n Breve*** |
|----------------------------|-------|----------|----------|---------|-----------------|--------------------|
| *Balanced Random Forest*   | Train | 0.8873   | 0.7700   | 0.9987  | 0.9937          | *Alta capacidad de detecci칩n de accidentes graves (recall ~0.88). Sobreajuste moderado debido al desbalance; mitigable con t칠cnicas como SMOTE si se requiere.* |
|                            | Test  | 0.7681   | 0.5920   | 0.8600  | 0.4644          | *Predicci칩n robusta para clase minoritaria, buen equilibrio entre precisi칩n y recall.* |
| *Easy Ensemble*            | Test  | 0.7490   | 0.6038   | 0.8563  | 0.4575          | *Resultados similares a Balanced RF, menor estabilidad y capacidad de generalizaci칩n.* |
| *Logistic Regression*      | Test  | 0.7492   | 0.6039   | 0.8640  | 0.4838          | *Buena detecci칩n de la clase minoritaria pero menor flexibilidad frente a patrones complejos.* |
| *Random Forest*            | Test  | 0.8084   | 0.3901   | 0.8084  | 0.6348          | *Buen desempe침o en la clase mayoritaria, pobre para la minoritaria.* |
| *Gradient Boosting*        | Test  | 0.8200   | 0.3045   | 0.8200  | 0.6006          | *Similar a Random Forest, 칰til para patrones generales pero limitado en clases desbalanceadas.* |


- *Balanced RF se identifica como el modelo m치s efectivo para este caso de estudio, equilibrando la detecci칩n de accidentes graves y leves.*  
- *Los modelos de ensemble (Balanced RF, Easy Ensemble) superan a modelos individuales en datasets desbalanceados.*  
- *Las m칠tricas de ROC-AUC y Average Precision confirman la capacidad de discriminaci칩n de los modelos en la clase minoritaria.*  
- *Se recomienda considerar t칠cnicas de oversampling como SMOTE si se desea reducir el sobreajuste y mejorar recall de la clase minoritaria.*  
- *Logistic Regression balanceada es simple y efectiva pero menos flexible para patrones complejos de accidentes.*  
- *Random Forest y Gradient Boosting funcionan bien para la clase mayoritaria, pero requieren ajustes o t칠cnicas adicionales para la minoritaria.*


---

##  游 *Despliegue con FastAPI*

- *El modelo se expone a trav칠s de un endpoint REST `/predict`.*
- *Se reciben inputs de las variables seleccionadas y se devuelve:*
  - *Predicci칩n: 0 = leve, 1 = grave*
  - *Probabilidad de accidente grave*


---
## 丘멆잺 *Disclaimer*

- *Los datos utilizados en este proyecto provienen de la plataforma [Kaggle](https://www.kaggle.com/) y se emplearon 칰nicamente con fines investigativos.*  
- *El modelo desarrollado est치 basado en los datos disponibles y su desempe침o refleja 칰nicamente las caracter칤sticas de ese dataset.*  
- *No se recomienda utilizar este modelo en entornos reales de seguridad vial sin una validaci칩n adicional exhaustiva y sin considerar la normativa y protocolos locales.*  
- *El modelo puede contener errores o generar predicciones incorrectas, especialmente en situaciones no representadas en los datos de entrenamiento, y no garantizan precisi칩n en escenarios del mundo real.*
- *Cualquier uso del modelo debe hacerse bajo responsabilidad del usuario y con precauciones adecuadas.*  


